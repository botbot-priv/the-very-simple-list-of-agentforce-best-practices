## Pattern: Narrow, Curated Knowledge beats â€œIndex Everythingâ€

**Intent**  
Improve answer quality and reduce costs by scoping retrieval to a **small, curated** knowledge set aligned to a **specific question set**.

---

### âœ… What Works
- **Be specific.** Frame the challenge.  
  For example: â€œWe need an Agent to answer our 10 most-asked customer questions, at the right time, using relevant knowledge.â€
- **Small, curated knowledge sets** (like a single FAQ object) **>** 100GB of unreviewed docs.

### âš ï¸ What Breaks
- Expecting an Agent to be an *all-knowing oracle*.  
- Ingesting massive, unreviewed & unstructured data sets.  
- Skipping **pre/post filtering** â‡’ poor quality + high cost.

### ğŸ’¡ Implications
- RAG at scale is often **fragile and expensive**.  
- **More data â‰  better answers.**  
- A **narrow scope** often wins: faster, cheaper, more reliable.  
- Overpromising frustrates customers when â€œAI knows everythingâ€ fails.

### ğŸ“Œ Guiding Principle
If you wouldnâ€™t train a **human** with that messy knowledge base, donâ€™t expect an **AI Agent** to succeed either.